{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drewwhite/Desktop/Programming/Projects/musical_journeys/venv/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "/Users/drewwhite/Desktop/Programming/Projects/musical_journeys/venv/lib/python3.7/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading ./data/genres_original/jazz/jazz.00054.wav. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = './data/genres_original'  # Path to dataset directory\n",
    "genres = os.listdir(data_dir)  # List of genre names\n",
    "\n",
    "dataset = []  # List to store MFCCs and genre labels\n",
    "for genre in genres:\n",
    "    genre_dir = os.path.join(data_dir, genre)  # Path to genre directory\n",
    "    for filename in os.listdir(genre_dir):\n",
    "        songname = os.path.join(genre_dir, filename)  # Path to song file\n",
    "        try:\n",
    "            y, sr = librosa.load(songname, duration=30)  # Load audio file with duration of 30 seconds\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # Extract MFCCs\n",
    "            dataset.append((mfcc, genre))  # Append MFCCs and genre label to dataset list\n",
    "        except:\n",
    "            print(f'Error loading {songname}. Skipping...')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = zip(*dataset)  # Unzip the MFCCs and genre labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Split into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Reshape and scale the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum number of frames in the dataset\n",
    "max_frames = max([x.shape[1] for x in X_train + X_test])\n",
    "\n",
    "# Pad or truncate the MFCCs to have the same number of frames\n",
    "X_train = np.array([np.pad(x, ((0, 0), (0, max_frames - x.shape[1])), mode='constant') for x in X_train])\n",
    "X_test = np.array([np.pad(x, ((0, 0), (0, max_frames - x.shape[1])), mode='constant') for x in X_test])\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(len(X_train), -1)).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(len(X_test), -1)).reshape(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train and evaluate the model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
